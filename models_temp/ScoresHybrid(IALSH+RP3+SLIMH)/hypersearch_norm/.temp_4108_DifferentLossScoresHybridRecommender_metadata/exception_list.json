["Traceback (most recent call last):\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 464, in _objective_function\n    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 336, in _evaluate_on_validation\n    result_df, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 271, in evaluateRecommender\n    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 481, in _run_evaluation_on_selected_users\n    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\BaseRecommender.py\", line 147, in recommend\n    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\HybridScores\\DifferentStructure.py\", line 99, in _compute_item_score\n    item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\nAttributeError: 'ThreeDifferentModelRecommender' object has no attribute 'recommender_3'\n", "Traceback (most recent call last):\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 464, in _objective_function\n    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 336, in _evaluate_on_validation\n    result_df, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 271, in evaluateRecommender\n    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 481, in _run_evaluation_on_selected_users\n    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\BaseRecommender.py\", line 147, in recommend\n    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\HybridScores\\DifferentStructure.py\", line 99, in _compute_item_score\n    item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\nAttributeError: 'ThreeDifferentModelRecommender' object has no attribute 'recommender_3'\n", "Traceback (most recent call last):\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 464, in _objective_function\n    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\HyperparameterTuning\\SearchAbstractClass.py\", line 336, in _evaluate_on_validation\n    result_df, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 271, in evaluateRecommender\n    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Evaluation\\Evaluator.py\", line 481, in _run_evaluation_on_selected_users\n    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\BaseRecommender.py\", line 147, in recommend\n    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n  File \"C:\\Programmi\\Programmazione\\Resources\\GitHub\\RecSys_Challenge2021\\Notebooks_HybridsRatings_KingPowa\\../RecSysRep\\Recommenders\\HybridScores\\DifferentStructure.py\", line 99, in _compute_item_score\n    item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\nAttributeError: 'ThreeDifferentModelRecommender' object has no attribute 'recommender_3'\n", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]